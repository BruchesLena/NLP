{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seminar_1_students.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq8dlr5EKL8J",
        "colab_type": "text"
      },
      "source": [
        "# Семинар 1. Jupyter Notebooks. NLTK. Морфологический анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV6OjaO5LTsR",
        "colab_type": "text"
      },
      "source": [
        "Jupyter Notebooks  - инструмент для разработки, визуализации и представления Ваших проектов. Он представляет собой набор ячеек (cells), в которых может быть текст в Markdown (как в этой ячейке)  или код (как например, в следующей). Запустите следующую ячейку с кодом (слева от ячейки \"run\" или ctrl+enter), чтобы посмотреть, как она работает."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgAOtvsKI0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2+3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrAJZ-VtOExA",
        "colab_type": "text"
      },
      "source": [
        "Или следующая:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrNPb0_NOEMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (2+3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBeDUumDObIK",
        "colab_type": "text"
      },
      "source": [
        "И ещё один пример:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N44N6SyxOfNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "  print (i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKbvzZVBO6Yz",
        "colab_type": "text"
      },
      "source": [
        "Или можно написать функцию в одной ячейке:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArNZSD1ZPBzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_name(name):\n",
        "  print ('Hello,', name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmV8i9JiPL4g",
        "colab_type": "text"
      },
      "source": [
        "...и вызвать эту функцию в другой ячейке (не забудьте запустить ячейку с функцией!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQZnzE-7PUaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_name('John')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ1NcVPmov_i",
        "colab_type": "text"
      },
      "source": [
        "NLTK - это библиотека для обработки текстов. Библиотека содержит несколько текстовых корпусов. Загрузим и импортируем один из них для дальнейшей работы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezxUV7EpKyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "sentences = len(brown.sents())\n",
        "print ('sentences:', sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-cj14j3qO5L",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на несколько предложений из этого корпуса:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Z7OkxTqT9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "  print (brown.sents()[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHbziJNdJRS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJa24hW9q7Ro",
        "colab_type": "text"
      },
      "source": [
        "Каждое предложение в этом корпусе представляет собой массив строк, каждая строка, в свою очередь является токеном.\n",
        "Ниже напишите код, который считает общее количество токенов в этом корпусе, количество уникальных токенов и 10 самых частых токенов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7JlqPUyrWj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdfqAqbLtWIv",
        "colab_type": "text"
      },
      "source": [
        "Часто при обработке текстов мы не хотим обрабатывать служебные или часто встречающиеся слова (стоп-слова). NLTK содержит списки стоп-слов для некоторых языков. Закончите код, удалив стоп-слова, и выведите на экран теперь 10 самых частых токенов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glXVm8H5uAdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "print (sw)\n",
        "# Ваш код"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJhadOaku77s",
        "colab_type": "text"
      },
      "source": [
        "Теперь сделаем частеречную разметку. Для начала загрузим и импортируем необходимые модули, затем посмотрим на список частей речи, который используется в NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3qZfr2nvQYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "\n",
        "nltk.help.upenn_tagset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA71yqwCv9Fp",
        "colab_type": "text"
      },
      "source": [
        "Теперь разметим предложение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gOTf7kawBaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = brown.sents()[0]\n",
        "tags = nltk.pos_tag(sentence)\n",
        "tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEcLP6ptwT6m",
        "colab_type": "text"
      },
      "source": [
        "Посчитайте количество каждой части речи в этом корпусе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsIusJzRwai2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ваш код"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-QRjKyJc8im",
        "colab_type": "text"
      },
      "source": [
        "Также в NLTK реализованы несколько алгоритмов для стемминга:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZFqLWwidGTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "\n",
        "words = ['saying', 'maximum', 'provision']\n",
        "for word in words:\n",
        "  print(porter_stemmer.stem(word), lancaster_stemmer.stem(word), snowball_stemmer.stem(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ4PwYIneOrP",
        "colab_type": "text"
      },
      "source": [
        "Добавьте свои слова, чтобы посмотреть на разницу алгоритмов стемминга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F9wQNjmeb52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# массив для Ваших слов:\n",
        "words = [] \n",
        "for word in words:\n",
        "  print(porter_stemmer.stem(word), lancaster_stemmer.stem(word), snowball_stemmer.stem(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p1reteKeg2g",
        "colab_type": "text"
      },
      "source": [
        "Лемматизатор в NLTK основан на WordNet'е."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dGne7WetYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "print(wordnet_lemmatizer.lemmatize('dogs'))\n",
        "print(wordnet_lemmatizer.lemmatize('are'))\n",
        "print(wordnet_lemmatizer.lemmatize('is'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ7czV4WfAUt",
        "colab_type": "text"
      },
      "source": [
        "Можно заметить, что формы 'are' и 'is' не приводятся к форме 'be'. Это случается из-за того, что по умолчанию все слова рассматриваются как существительные. Можно указать нужную часть речь слова, чтобы получить корректную лемму:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf1XmCNtfx7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(wordnet_lemmatizer.lemmatize('are', pos='v'))\n",
        "print(wordnet_lemmatizer.lemmatize('is', pos='v'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ99lRqTf-my",
        "colab_type": "text"
      },
      "source": [
        "Все предыдущие примеры мы брали из корпуса, где слова уже разбиты на токены. Чтобы выделить токены из произвольной строки, нужно воспользоваться токенизатором:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAbDwu7VgRf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "sentence = 'I love NLP'\n",
        "tokens = word_tokenize(sentence)\n",
        "tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfriu92_g04N",
        "colab_type": "text"
      },
      "source": [
        "Теперь возьмите любое предложение и :\n",
        "\n",
        "\n",
        "1.   Разбейте его на токены;\n",
        "2.   Для каждого токена определите его часть речи;\n",
        "3.  Выполните для каждого токена стемминг и лемматизацию.\n",
        "4. Удалите из предложения (списка токенов) все стоп-слова\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-v4EuehcwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_sentence = ''\n",
        "# Ваш код"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}